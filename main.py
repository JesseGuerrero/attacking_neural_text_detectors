import shutil

import numpy as np
from detector import Detector
from attacks import attack
from utils import load_txt, write_txt, load_json_file, get_results, runcmd
import os
from tqdm import tqdm
import time
import subprocess

'''
The dataset originally given into this model is 100% synthetic, generated by GPT-2. we are trying to see if they can be fooled for human
There are different types of attacks/experiments organized by keyword in the attacks.py file

EXPERIMENT_NAME is the name of the folder to hold the data files
ADVERSARIAL_TYPE is the type of changes we make to each text.
TEXT_TO_CHANGE is the number of texts to make adversarial.

Adversarial Types:
-'do-nothing': Nothing is done
-'replace-char': Replace homoglyphs below
-'random-order-replace-char': Same as replace char except the input text lines are shuffled
-'misspelling': Replaces certain words with misspellings from misspellings.json.
'''
EXPERIMENT_NAME = "50_normal"
ADVERSARIAL_TYPE = "do-nothing"
TEXT_TO_CHANGE = 50
HOMOGLYPH_REPLACEMENT = [['e', 'ะต']]

def run_experiment(
	homoglyphs, 
	attack_type, 
	detector,
	experiment_name,
	data_file,
	percent_change = None,
	misspelling_dict = None,
	throwout=False):

	start_time = time.time()
	print("max length: " + str(detector.tokenizer.max_len))


	out_path = './experimental_results/' + experiment_name + '/'
	adv_text_path = out_path + 'adv_texts/'
	numerical_results_path = out_path + 'results.txt'
	num_changes_path = out_path +'num_changes.txt'
	if os.path.isdir('./experimental_results/'):
		if os.path.exists(adv_text_path):
			shutil.rmtree(adv_text_path)
		if os.path.exists(out_path):
			shutil.rmtree(out_path)
		if os.path.exists(numerical_results_path):
			open(numerical_results_path, 'w').close()  # Blank out the files
		if os.path.exists(num_changes_path):
			open(num_changes_path, 'w').close()
	if not os.path.isdir('./experimental_results/'):
		os.mkdir("./experimental_results/")
		open("./experimental_results/blank.txt", 'w').close()

	print('Running Experiment: {} ...'.format(experiment_name))

	if not os.path.isdir(out_path):
		os.mkdir(out_path)
		os.mkdir(adv_text_path)

	text_list = load_json_file(data_file)

	_range = tqdm(range(TEXT_TO_CHANGE))#len(text_list)))
	i = 0

	for _ in _range:

		text_to_use = detector.tokenizer.decode(
			detector.tokenizer.encode(text_list[i], max_length=detector.tokenizer.max_len))[3:-4]

		adv_text, num_changes = attack(
			text_to_use, homoglyphs, attack_type, percent_change, misspelling_dict, throwout)
		if throwout and (adv_text==text_to_use):
			pass

		else:

			write_txt(adv_text_path+str(i)+'.txt', adv_text)

			probs = detector.predict(adv_text)

			human_prob = probs[1]

			_range.set_description('{} | {}'.format(i, human_prob))

			with open(numerical_results_path, 'a') as f:
				f.write(str(human_prob) + ' ')
			f.close()

			with open(num_changes_path, 'a') as f:
				f.write(str(num_changes)+' ')
			f.close()

		i+=1

	end_time = time.time()

	print('Time to complete experiment (minutes):', (end_time-start_time)/60.)


import wget
if __name__ == '__main__':
	if not os.path.exists("./detector-large.pt"):
		print("Downloading detector...")
		wget.download("https://openaipublic.azureedge.net/gpt-2/detector-models/v1/detector-large.pt")
	data_file = './data/xl-1542M-k40.test.jsonl'

	detector = Detector()

	run_experiment(
		HOMOGLYPH_REPLACEMENT,
		ADVERSARIAL_TYPE,
		detector,
		EXPERIMENT_NAME,
		data_file,
		None,
		None,
		None)

	get_results(EXPERIMENT_NAME)
